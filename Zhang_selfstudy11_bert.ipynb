{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jiyuan_selfstudy11_bert.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "EQHcJlAgHZ2o",
        "colab_type": "code",
        "outputId": "994f718f-890b-4c69-9c60-29cfa263f40d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install bert-text"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-text\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/1d/3c7226547cd6a2ba54586dfd80a49f64a0936f9bcb945a4686e843a1956a/bert_text-5.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from bert-text) (0.23.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from bert-text) (4.28.1)\n",
            "Collecting bert-tensorflow (from bert-text)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 3.3MB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu (from bert-text)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 345.2MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (from bert-text) (0.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-text) (1.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->bert-text) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas->bert-text) (1.16.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->bert-text) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (0.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.0.9)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.13.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (0.7.1)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.13.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.0.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (0.33.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu->bert-text) (40.9.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu->bert-text) (2.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu->bert-text) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu->bert-text) (3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu->bert-text) (2.8.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu->bert-text) (5.1.3)\n",
            "Installing collected packages: bert-tensorflow, tensorflow-gpu, bert-text\n",
            "Successfully installed bert-tensorflow-1.0.1 bert-text-5.0.0 tensorflow-gpu-1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oZFDseXWHiSz",
        "colab_type": "code",
        "outputId": "3d7b6feb-6d81-4074-fec8-5f13627d1ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "from bert_text import run_on_dfs"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0416 01:32:16.693131 139892314072960 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "R4pBwSidH4CT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vEGtiE42IDyj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(\"imdb-review.pickle\", 'rb') as f:\n",
        "  train, test = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P6wlSR8NIKHS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = train.sample(len(train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qCoK42AGIXsS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "myparam = {\n",
        "    \"DATA_COLUMN\": \"text\",\n",
        "    \"LABEL_COLUMN\": \"sentiment\",\n",
        "    \"LEARNING_RATE\": 2e-5,\n",
        "    \"NUM_TRAIN_EPOCHS\": 3\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SUwqGJuIfgap",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YoOVNBr7IsjS",
        "colab_type": "code",
        "outputId": "78dd68eb-b1de-45d7-c8dd-1fd9809c852c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6102
        }
      },
      "cell_type": "code",
      "source": [
        "result, estimator = run_on_dfs(train, test, **myparam)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0416 01:32:25.693259 139892314072960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:27.778960 139892314072960 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.310696 139892314072960 run_classifier.py:774] Writing example 0 of 25000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.321321 139892314072960 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.332325 139892314072960 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] okay , let me break it down for you guys . . . it ' s horrible ! < br / > < br / > if roger ku ##mble did such a fancy job on the first cruel intentions then why did he do such a bad job on this . i ' m sorry but this movie is stupid , true it may have improved if its series was ever aired but lets be realistic . . . this movie a cr ##ock ! a lot of bad acting * note the shower scene * \" kissing cousins \" ? ? ? ? ? ? what kind of line is that ? \" slip ##ery when wet \" ? ? ? ? ? ? [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.333814 139892314072960 run_classifier.py:464] tokens: [CLS] okay , let me break it down for you guys . . . it ' s horrible ! < br / > < br / > if roger ku ##mble did such a fancy job on the first cruel intentions then why did he do such a bad job on this . i ' m sorry but this movie is stupid , true it may have improved if its series was ever aired but lets be realistic . . . this movie a cr ##ock ! a lot of bad acting * note the shower scene * \" kissing cousins \" ? ? ? ? ? ? what kind of line is that ? \" slip ##ery when wet \" ? ? ? ? ? ? [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3100 1010 2292 2033 3338 2009 2091 2005 2017 4364 1012 1012 1012 2009 1005 1055 9202 999 1026 7987 1013 1028 1026 7987 1013 1028 2065 5074 13970 19661 2106 2107 1037 11281 3105 2006 1996 2034 10311 11174 2059 2339 2106 2002 2079 2107 1037 2919 3105 2006 2023 1012 1045 1005 1049 3374 2021 2023 3185 2003 5236 1010 2995 2009 2089 2031 5301 2065 2049 2186 2001 2412 4836 2021 11082 2022 12689 1012 1012 1012 2023 3185 1037 13675 7432 999 1037 2843 1997 2919 3772 1008 3602 1996 6457 3496 1008 1000 7618 12334 1000 1029 1029 1029 1029 1029 1029 2054 2785 1997 2240 2003 2008 1029 1000 7540 7301 2043 4954 1000 1029 1029 1029 1029 1029 1029 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.336475 139892314072960 run_classifier.py:465] input_ids: 101 3100 1010 2292 2033 3338 2009 2091 2005 2017 4364 1012 1012 1012 2009 1005 1055 9202 999 1026 7987 1013 1028 1026 7987 1013 1028 2065 5074 13970 19661 2106 2107 1037 11281 3105 2006 1996 2034 10311 11174 2059 2339 2106 2002 2079 2107 1037 2919 3105 2006 2023 1012 1045 1005 1049 3374 2021 2023 3185 2003 5236 1010 2995 2009 2089 2031 5301 2065 2049 2186 2001 2412 4836 2021 11082 2022 12689 1012 1012 1012 2023 3185 1037 13675 7432 999 1037 2843 1997 2919 3772 1008 3602 1996 6457 3496 1008 1000 7618 12334 1000 1029 1029 1029 1029 1029 1029 2054 2785 1997 2240 2003 2008 1029 1000 7540 7301 2043 4954 1000 1029 1029 1029 1029 1029 1029 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.338849 139892314072960 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.340759 139892314072960 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.346717 139892314072960 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.370847 139892314072960 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.372259 139892314072960 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this makes the third er ##rol morris movie i ' ve seen , and i ' m increasingly not liking his style . he seems to find very interesting and varied characters , great personalities to create documentaries for , and then with tongue - in - cheek editing make fun of everything they are about . it ' s never really a direct car ##ica ##tura ##tion of them and morris seems most of the time to be saying , \" but no , no , these people are really fascinating , really ! \" , but there ' s always these subtle little can ##ted angles and not - so - subtle editing techniques that show that morris seems to be mocking them behind [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.374042 139892314072960 run_classifier.py:464] tokens: [CLS] this makes the third er ##rol morris movie i ' ve seen , and i ' m increasingly not liking his style . he seems to find very interesting and varied characters , great personalities to create documentaries for , and then with tongue - in - cheek editing make fun of everything they are about . it ' s never really a direct car ##ica ##tura ##tion of them and morris seems most of the time to be saying , \" but no , no , these people are really fascinating , really ! \" , but there ' s always these subtle little can ##ted angles and not - so - subtle editing techniques that show that morris seems to be mocking them behind [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 3084 1996 2353 9413 13153 6384 3185 1045 1005 2310 2464 1010 1998 1045 1005 1049 6233 2025 16663 2010 2806 1012 2002 3849 2000 2424 2200 5875 1998 9426 3494 1010 2307 12857 2000 3443 15693 2005 1010 1998 2059 2007 4416 1011 1999 1011 5048 9260 2191 4569 1997 2673 2027 2024 2055 1012 2009 1005 1055 2196 2428 1037 3622 2482 5555 27431 3508 1997 2068 1998 6384 3849 2087 1997 1996 2051 2000 2022 3038 1010 1000 2021 2053 1010 2053 1010 2122 2111 2024 2428 17160 1010 2428 999 1000 1010 2021 2045 1005 1055 2467 2122 11259 2210 2064 3064 12113 1998 2025 1011 2061 1011 11259 9260 5461 2008 2265 2008 6384 3849 2000 2022 19545 2068 2369 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.376950 139892314072960 run_classifier.py:465] input_ids: 101 2023 3084 1996 2353 9413 13153 6384 3185 1045 1005 2310 2464 1010 1998 1045 1005 1049 6233 2025 16663 2010 2806 1012 2002 3849 2000 2424 2200 5875 1998 9426 3494 1010 2307 12857 2000 3443 15693 2005 1010 1998 2059 2007 4416 1011 1999 1011 5048 9260 2191 4569 1997 2673 2027 2024 2055 1012 2009 1005 1055 2196 2428 1037 3622 2482 5555 27431 3508 1997 2068 1998 6384 3849 2087 1997 1996 2051 2000 2022 3038 1010 1000 2021 2053 1010 2053 1010 2122 2111 2024 2428 17160 1010 2428 999 1000 1010 2021 2045 1005 1055 2467 2122 11259 2210 2064 3064 12113 1998 2025 1011 2061 1011 11259 9260 5461 2008 2265 2008 6384 3849 2000 2022 19545 2068 2369 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.378887 139892314072960 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.380837 139892314072960 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.382498 139892314072960 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.388038 139892314072960 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.389728 139892314072960 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] cu ##sack does his best david ni ##ven in this one , although i don ' t know if anyone besides me noticed it . < br / > < br / > when seen with this in mind , its a delicious ##ly over saturated ' wants to be taken more seriously than austin powers but still be pretty d * mn funny ' re ##working of an under - appreciated comedy classic . < br / > < br / > hillary duff does an over sexual ##ized britney spears lap dance version of mata bond . the writers built a little reverse o ##ed ##ip ##us twist into the plot - interesting choice . < br / > < br / > i [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.392518 139892314072960 run_classifier.py:464] tokens: [CLS] cu ##sack does his best david ni ##ven in this one , although i don ' t know if anyone besides me noticed it . < br / > < br / > when seen with this in mind , its a delicious ##ly over saturated ' wants to be taken more seriously than austin powers but still be pretty d * mn funny ' re ##working of an under - appreciated comedy classic . < br / > < br / > hillary duff does an over sexual ##ized britney spears lap dance version of mata bond . the writers built a little reverse o ##ed ##ip ##us twist into the plot - interesting choice . < br / > < br / > i [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 12731 25607 2515 2010 2190 2585 9152 8159 1999 2023 2028 1010 2348 1045 2123 1005 1056 2113 2065 3087 4661 2033 4384 2009 1012 1026 7987 1013 1028 1026 7987 1013 1028 2043 2464 2007 2023 1999 2568 1010 2049 1037 12090 2135 2058 23489 1005 4122 2000 2022 2579 2062 5667 2084 5899 4204 2021 2145 2022 3492 1040 1008 24098 6057 1005 2128 21398 1997 2019 2104 1011 12315 4038 4438 1012 1026 7987 1013 1028 1026 7987 1013 1028 18520 21019 2515 2019 2058 4424 3550 29168 13957 5001 3153 2544 1997 22640 5416 1012 1996 4898 2328 1037 2210 7901 1051 2098 11514 2271 9792 2046 1996 5436 1011 5875 3601 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.394258 139892314072960 run_classifier.py:465] input_ids: 101 12731 25607 2515 2010 2190 2585 9152 8159 1999 2023 2028 1010 2348 1045 2123 1005 1056 2113 2065 3087 4661 2033 4384 2009 1012 1026 7987 1013 1028 1026 7987 1013 1028 2043 2464 2007 2023 1999 2568 1010 2049 1037 12090 2135 2058 23489 1005 4122 2000 2022 2579 2062 5667 2084 5899 4204 2021 2145 2022 3492 1040 1008 24098 6057 1005 2128 21398 1997 2019 2104 1011 12315 4038 4438 1012 1026 7987 1013 1028 1026 7987 1013 1028 18520 21019 2515 2019 2058 4424 3550 29168 13957 5001 3153 2544 1997 22640 5416 1012 1996 4898 2328 1037 2210 7901 1051 2098 11514 2271 9792 2046 1996 5436 1011 5875 3601 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.396107 139892314072960 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.397843 139892314072960 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.399621 139892314072960 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.405302 139892314072960 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.407126 139892314072960 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] \" ask the dust \" looked intriguing from the trailer , and we especially like all of the actors . unfortunately , the movie was not compelling enough to be considered drama , and it wasn ' t funny enough to be a comedy . it practically seemed to sat ##iri ##ze itself , and to no entertaining effect . after seventy minutes of waiting for this thing to get better , my wife and i walked out , val ##uing not having wasted any more time on such nonsense . it simply was not interesting , moving , funny nor artistic . it appears as though it were written , produced and directed by a high school kid ; worse yet , it was such [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.408977 139892314072960 run_classifier.py:464] tokens: [CLS] \" ask the dust \" looked intriguing from the trailer , and we especially like all of the actors . unfortunately , the movie was not compelling enough to be considered drama , and it wasn ' t funny enough to be a comedy . it practically seemed to sat ##iri ##ze itself , and to no entertaining effect . after seventy minutes of waiting for this thing to get better , my wife and i walked out , val ##uing not having wasted any more time on such nonsense . it simply was not interesting , moving , funny nor artistic . it appears as though it were written , produced and directed by a high school kid ; worse yet , it was such [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1000 3198 1996 6497 1000 2246 23824 2013 1996 9117 1010 1998 2057 2926 2066 2035 1997 1996 5889 1012 6854 1010 1996 3185 2001 2025 17075 2438 2000 2022 2641 3689 1010 1998 2009 2347 1005 1056 6057 2438 2000 2022 1037 4038 1012 2009 8134 2790 2000 2938 15735 4371 2993 1010 1998 2000 2053 14036 3466 1012 2044 10920 2781 1997 3403 2005 2023 2518 2000 2131 2488 1010 2026 2564 1998 1045 2939 2041 1010 11748 25165 2025 2383 13842 2151 2062 2051 2006 2107 14652 1012 2009 3432 2001 2025 5875 1010 3048 1010 6057 4496 6018 1012 2009 3544 2004 2295 2009 2020 2517 1010 2550 1998 2856 2011 1037 2152 2082 4845 1025 4788 2664 1010 2009 2001 2107 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.410797 139892314072960 run_classifier.py:465] input_ids: 101 1000 3198 1996 6497 1000 2246 23824 2013 1996 9117 1010 1998 2057 2926 2066 2035 1997 1996 5889 1012 6854 1010 1996 3185 2001 2025 17075 2438 2000 2022 2641 3689 1010 1998 2009 2347 1005 1056 6057 2438 2000 2022 1037 4038 1012 2009 8134 2790 2000 2938 15735 4371 2993 1010 1998 2000 2053 14036 3466 1012 2044 10920 2781 1997 3403 2005 2023 2518 2000 2131 2488 1010 2026 2564 1998 1045 2939 2041 1010 11748 25165 2025 2383 13842 2151 2062 2051 2006 2107 14652 1012 2009 3432 2001 2025 5875 1010 3048 1010 6057 4496 6018 1012 2009 3544 2004 2295 2009 2020 2517 1010 2550 1998 2856 2011 1037 2152 2082 4845 1025 4788 2664 1010 2009 2001 2107 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.412502 139892314072960 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.414102 139892314072960 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.415946 139892314072960 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.430261 139892314072960 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.432293 139892314072960 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] at the time of writing this review it would seem that over 50 % of im ##db voters had given this film a rating of either a 10 or a 1 . i can only sur ##mise then that those giving it a 10 were either cast or crew members . < br / > < br / > they say that given enough monkeys and enough time and enough type ##writer ##s , those monkeys , just by random pro ##dding ##s at the keyboard , would eventually type out the complete works of shakespeare . however , i seriously doubt that given the same number of monkeys and time , you could find a single one to give this movie a rating of 10 [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.434175 139892314072960 run_classifier.py:464] tokens: [CLS] at the time of writing this review it would seem that over 50 % of im ##db voters had given this film a rating of either a 10 or a 1 . i can only sur ##mise then that those giving it a 10 were either cast or crew members . < br / > < br / > they say that given enough monkeys and enough time and enough type ##writer ##s , those monkeys , just by random pro ##dding ##s at the keyboard , would eventually type out the complete works of shakespeare . however , i seriously doubt that given the same number of monkeys and time , you could find a single one to give this movie a rating of 10 [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2012 1996 2051 1997 3015 2023 3319 2009 2052 4025 2008 2058 2753 1003 1997 10047 18939 7206 2018 2445 2023 2143 1037 5790 1997 2593 1037 2184 2030 1037 1015 1012 1045 2064 2069 7505 28732 2059 2008 2216 3228 2009 1037 2184 2020 2593 3459 2030 3626 2372 1012 1026 7987 1013 1028 1026 7987 1013 1028 2027 2360 2008 2445 2438 17059 1998 2438 2051 1998 2438 2828 15994 2015 1010 2216 17059 1010 2074 2011 6721 4013 27027 2015 2012 1996 9019 1010 2052 2776 2828 2041 1996 3143 2573 1997 8101 1012 2174 1010 1045 5667 4797 2008 2445 1996 2168 2193 1997 17059 1998 2051 1010 2017 2071 2424 1037 2309 2028 2000 2507 2023 3185 1037 5790 1997 2184 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.436191 139892314072960 run_classifier.py:465] input_ids: 101 2012 1996 2051 1997 3015 2023 3319 2009 2052 4025 2008 2058 2753 1003 1997 10047 18939 7206 2018 2445 2023 2143 1037 5790 1997 2593 1037 2184 2030 1037 1015 1012 1045 2064 2069 7505 28732 2059 2008 2216 3228 2009 1037 2184 2020 2593 3459 2030 3626 2372 1012 1026 7987 1013 1028 1026 7987 1013 1028 2027 2360 2008 2445 2438 17059 1998 2438 2051 1998 2438 2828 15994 2015 1010 2216 17059 1010 2074 2011 6721 4013 27027 2015 2012 1996 9019 1010 2052 2776 2828 2041 1996 3143 2573 1997 8101 1012 2174 1010 1045 5667 4797 2008 2445 1996 2168 2193 1997 17059 1998 2051 1010 2017 2071 2424 1037 2309 2028 2000 2507 2023 3185 1037 5790 1997 2184 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.438094 139892314072960 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.439931 139892314072960 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:32:29.441592 139892314072960 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:33:20.907445 139892314072960 run_classifier.py:774] Writing example 10000 of 25000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:11.135516 139892314072960 run_classifier.py:774] Writing example 20000 of 25000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.520090 139892314072960 run_classifier.py:774] Writing example 0 of 25000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.530668 139892314072960 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.535438 139892314072960 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] based on an actual story , john boo ##rman shows the struggle of an american doctor , whose husband and son were murdered and she was continually plagued with her loss . a holiday to burma with her sister seemed like a good idea to get away from it all , but when her passport was stolen in rang ##oon , she could not leave the country with her sister , and was forced to stay back until she could get i . d . papers from the american embassy . to fill in a day before she could fly out , she took a trip into the countryside with a tour guide . \" i tried finding something in those stone statues , but nothing [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.541610 139892314072960 run_classifier.py:464] tokens: [CLS] based on an actual story , john boo ##rman shows the struggle of an american doctor , whose husband and son were murdered and she was continually plagued with her loss . a holiday to burma with her sister seemed like a good idea to get away from it all , but when her passport was stolen in rang ##oon , she could not leave the country with her sister , and was forced to stay back until she could get i . d . papers from the american embassy . to fill in a day before she could fly out , she took a trip into the countryside with a tour guide . \" i tried finding something in those stone statues , but nothing [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2241 2006 2019 5025 2466 1010 2198 22017 14515 3065 1996 5998 1997 2019 2137 3460 1010 3005 3129 1998 2365 2020 7129 1998 2016 2001 14678 17808 2007 2014 3279 1012 1037 6209 2000 11050 2007 2014 2905 2790 2066 1037 2204 2801 2000 2131 2185 2013 2009 2035 1010 2021 2043 2014 12293 2001 7376 1999 8369 7828 1010 2016 2071 2025 2681 1996 2406 2007 2014 2905 1010 1998 2001 3140 2000 2994 2067 2127 2016 2071 2131 1045 1012 1040 1012 4981 2013 1996 2137 8408 1012 2000 6039 1999 1037 2154 2077 2016 2071 4875 2041 1010 2016 2165 1037 4440 2046 1996 10833 2007 1037 2778 5009 1012 1000 1045 2699 4531 2242 1999 2216 2962 11342 1010 2021 2498 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.544357 139892314072960 run_classifier.py:465] input_ids: 101 2241 2006 2019 5025 2466 1010 2198 22017 14515 3065 1996 5998 1997 2019 2137 3460 1010 3005 3129 1998 2365 2020 7129 1998 2016 2001 14678 17808 2007 2014 3279 1012 1037 6209 2000 11050 2007 2014 2905 2790 2066 1037 2204 2801 2000 2131 2185 2013 2009 2035 1010 2021 2043 2014 12293 2001 7376 1999 8369 7828 1010 2016 2071 2025 2681 1996 2406 2007 2014 2905 1010 1998 2001 3140 2000 2994 2067 2127 2016 2071 2131 1045 1012 1040 1012 4981 2013 1996 2137 8408 1012 2000 6039 1999 1037 2154 2077 2016 2071 4875 2041 1010 2016 2165 1037 4440 2046 1996 10833 2007 1037 2778 5009 1012 1000 1045 2699 4531 2242 1999 2216 2962 11342 1010 2021 2498 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.546980 139892314072960 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.551260 139892314072960 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.553938 139892314072960 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.562102 139892314072960 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.565590 139892314072960 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this is a gem . as a film four production - the anticipated quality was indeed delivered . shot with great style that reminded me some er ##rol morris films , well arranged and simply gripping . it ' s long yet ho ##rri ##fying to the point it ' s ex ##cr ##uc ##iating . we know something bad happened ( one can guess by the lack of participation of a person in the interviews ) but we are compelled to see it , a bit like a car accident in slow motion . the story spans most con ##ce ##iva ##ble aspects and unlike some documentaries did not try and refrain from showing the grimm ##er sides of the stories , as also dealing [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.571088 139892314072960 run_classifier.py:464] tokens: [CLS] this is a gem . as a film four production - the anticipated quality was indeed delivered . shot with great style that reminded me some er ##rol morris films , well arranged and simply gripping . it ' s long yet ho ##rri ##fying to the point it ' s ex ##cr ##uc ##iating . we know something bad happened ( one can guess by the lack of participation of a person in the interviews ) but we are compelled to see it , a bit like a car accident in slow motion . the story spans most con ##ce ##iva ##ble aspects and unlike some documentaries did not try and refrain from showing the grimm ##er sides of the stories , as also dealing [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 2003 1037 17070 1012 2004 1037 2143 2176 2537 1011 1996 11436 3737 2001 5262 5359 1012 2915 2007 2307 2806 2008 6966 2033 2070 9413 13153 6384 3152 1010 2092 5412 1998 3432 13940 1012 2009 1005 1055 2146 2664 7570 18752 14116 2000 1996 2391 2009 1005 1055 4654 26775 14194 15370 1012 2057 2113 2242 2919 3047 1006 2028 2064 3984 2011 1996 3768 1997 6577 1997 1037 2711 1999 1996 7636 1007 2021 2057 2024 15055 2000 2156 2009 1010 1037 2978 2066 1037 2482 4926 1999 4030 4367 1012 1996 2466 14798 2087 9530 3401 11444 3468 5919 1998 4406 2070 15693 2106 2025 3046 1998 20703 2013 4760 1996 24287 2121 3903 1997 1996 3441 1010 2004 2036 7149 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.572725 139892314072960 run_classifier.py:465] input_ids: 101 2023 2003 1037 17070 1012 2004 1037 2143 2176 2537 1011 1996 11436 3737 2001 5262 5359 1012 2915 2007 2307 2806 2008 6966 2033 2070 9413 13153 6384 3152 1010 2092 5412 1998 3432 13940 1012 2009 1005 1055 2146 2664 7570 18752 14116 2000 1996 2391 2009 1005 1055 4654 26775 14194 15370 1012 2057 2113 2242 2919 3047 1006 2028 2064 3984 2011 1996 3768 1997 6577 1997 1037 2711 1999 1996 7636 1007 2021 2057 2024 15055 2000 2156 2009 1010 1037 2978 2066 1037 2482 4926 1999 4030 4367 1012 1996 2466 14798 2087 9530 3401 11444 3468 5919 1998 4406 2070 15693 2106 2025 3046 1998 20703 2013 4760 1996 24287 2121 3903 1997 1996 3441 1010 2004 2036 7149 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.574434 139892314072960 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.577065 139892314072960 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.581856 139892314072960 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.590389 139892314072960 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.592826 139892314072960 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i really like this show . it has drama , romance , and comedy all rolled into one . i am 28 and i am a married mother , so i can identify both with lore ##lei ' s and rory ' s experiences in the show . i have been watching mostly the repeats on the family channel lately , so i am not up - to - date on what is going on now . i think females would like this show more than males , but i know some men out there would enjoy it ! i really like that is an hour long and not a half hour , as th hour seems to fly by when i am watching it ! [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.596646 139892314072960 run_classifier.py:464] tokens: [CLS] i really like this show . it has drama , romance , and comedy all rolled into one . i am 28 and i am a married mother , so i can identify both with lore ##lei ' s and rory ' s experiences in the show . i have been watching mostly the repeats on the family channel lately , so i am not up - to - date on what is going on now . i think females would like this show more than males , but i know some men out there would enjoy it ! i really like that is an hour long and not a half hour , as th hour seems to fly by when i am watching it ! [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2428 2066 2023 2265 1012 2009 2038 3689 1010 7472 1010 1998 4038 2035 4565 2046 2028 1012 1045 2572 2654 1998 1045 2572 1037 2496 2388 1010 2061 1045 2064 6709 2119 2007 19544 23057 1005 1055 1998 14285 1005 1055 6322 1999 1996 2265 1012 1045 2031 2042 3666 3262 1996 17993 2006 1996 2155 3149 9906 1010 2061 1045 2572 2025 2039 1011 2000 1011 3058 2006 2054 2003 2183 2006 2085 1012 1045 2228 3801 2052 2066 2023 2265 2062 2084 3767 1010 2021 1045 2113 2070 2273 2041 2045 2052 5959 2009 999 1045 2428 2066 2008 2003 2019 3178 2146 1998 2025 1037 2431 3178 1010 2004 16215 3178 3849 2000 4875 2011 2043 1045 2572 3666 2009 999 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.599116 139892314072960 run_classifier.py:465] input_ids: 101 1045 2428 2066 2023 2265 1012 2009 2038 3689 1010 7472 1010 1998 4038 2035 4565 2046 2028 1012 1045 2572 2654 1998 1045 2572 1037 2496 2388 1010 2061 1045 2064 6709 2119 2007 19544 23057 1005 1055 1998 14285 1005 1055 6322 1999 1996 2265 1012 1045 2031 2042 3666 3262 1996 17993 2006 1996 2155 3149 9906 1010 2061 1045 2572 2025 2039 1011 2000 1011 3058 2006 2054 2003 2183 2006 2085 1012 1045 2228 3801 2052 2066 2023 2265 2062 2084 3767 1010 2021 1045 2113 2070 2273 2041 2045 2052 5959 2009 999 1045 2428 2066 2008 2003 2019 3178 2146 1998 2025 1037 2431 3178 1010 2004 16215 3178 3849 2000 4875 2011 2043 1045 2572 3666 2009 999 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.602674 139892314072960 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.605134 139892314072960 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.608593 139892314072960 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.615306 139892314072960 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.618674 139892314072960 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this is the best 3 - d experience disney has at their theme ##park ##s . this is certainly better than their original 1960 ' s acid - trip film that was in it ' s place , is leagues better than \" honey i sh ##run ##k the audience \" ( and far more fun ) , barely squeak ##s by the mu ##ppet ##vision 3 - d movie at disney - mgm and can even beat the original 3 - d \" movie experience \" captain e ##o . this film re ##li ##ves some of disney ' s greatest musical hits from ala ##ddin , the little mermaid , and others , and brought a smile to my face throughout the entire show [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.620303 139892314072960 run_classifier.py:464] tokens: [CLS] this is the best 3 - d experience disney has at their theme ##park ##s . this is certainly better than their original 1960 ' s acid - trip film that was in it ' s place , is leagues better than \" honey i sh ##run ##k the audience \" ( and far more fun ) , barely squeak ##s by the mu ##ppet ##vision 3 - d movie at disney - mgm and can even beat the original 3 - d \" movie experience \" captain e ##o . this film re ##li ##ves some of disney ' s greatest musical hits from ala ##ddin , the little mermaid , and others , and brought a smile to my face throughout the entire show [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 2003 1996 2190 1017 1011 1040 3325 6373 2038 2012 2037 4323 14432 2015 1012 2023 2003 5121 2488 2084 2037 2434 3624 1005 1055 5648 1011 4440 2143 2008 2001 1999 2009 1005 1055 2173 1010 2003 8121 2488 2084 1000 6861 1045 14021 15532 2243 1996 4378 1000 1006 1998 2521 2062 4569 1007 1010 4510 29552 2015 2011 1996 14163 29519 17084 1017 1011 1040 3185 2012 6373 1011 15418 1998 2064 2130 3786 1996 2434 1017 1011 1040 1000 3185 3325 1000 2952 1041 2080 1012 2023 2143 2128 3669 6961 2070 1997 6373 1005 1055 4602 3315 4978 2013 21862 18277 1010 1996 2210 22322 1010 1998 2500 1010 1998 2716 1037 2868 2000 2026 2227 2802 1996 2972 2265 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.621910 139892314072960 run_classifier.py:465] input_ids: 101 2023 2003 1996 2190 1017 1011 1040 3325 6373 2038 2012 2037 4323 14432 2015 1012 2023 2003 5121 2488 2084 2037 2434 3624 1005 1055 5648 1011 4440 2143 2008 2001 1999 2009 1005 1055 2173 1010 2003 8121 2488 2084 1000 6861 1045 14021 15532 2243 1996 4378 1000 1006 1998 2521 2062 4569 1007 1010 4510 29552 2015 2011 1996 14163 29519 17084 1017 1011 1040 3185 2012 6373 1011 15418 1998 2064 2130 3786 1996 2434 1017 1011 1040 1000 3185 3325 1000 2952 1041 2080 1012 2023 2143 2128 3669 6961 2070 1997 6373 1005 1055 4602 3315 4978 2013 21862 18277 1010 1996 2210 22322 1010 1998 2500 1010 1998 2716 1037 2868 2000 2026 2227 2802 1996 2972 2265 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.623819 139892314072960 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.625561 139892314072960 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.628449 139892314072960 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.637174 139892314072960 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.639016 139892314072960 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] of the korean movies i ' ve seen , only three had really stuck with me . the first is the excellent horror a tale of two sisters . the second and third - and now fourth too - have all been park chan woo ##k ' s movies , namely old ##boy , sympathy for lady vengeance ) , and now thirst . < br / > < br / > park kinda reminds me of quentin tara ##ntino with his ir ##re ##vere ##nce towards convention . all his movies are shocking , but not in a gr ##at ##uit ##ous sense . it ' s more like he shows us what we don ' t expect to see - typically situations that go [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.641362 139892314072960 run_classifier.py:464] tokens: [CLS] of the korean movies i ' ve seen , only three had really stuck with me . the first is the excellent horror a tale of two sisters . the second and third - and now fourth too - have all been park chan woo ##k ' s movies , namely old ##boy , sympathy for lady vengeance ) , and now thirst . < br / > < br / > park kinda reminds me of quentin tara ##ntino with his ir ##re ##vere ##nce towards convention . all his movies are shocking , but not in a gr ##at ##uit ##ous sense . it ' s more like he shows us what we don ' t expect to see - typically situations that go [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1997 1996 4759 5691 1045 1005 2310 2464 1010 2069 2093 2018 2428 5881 2007 2033 1012 1996 2034 2003 1996 6581 5469 1037 6925 1997 2048 5208 1012 1996 2117 1998 2353 1011 1998 2085 2959 2205 1011 2031 2035 2042 2380 9212 15854 2243 1005 1055 5691 1010 8419 2214 11097 1010 11883 2005 3203 14096 1007 1010 1998 2085 21810 1012 1026 7987 1013 1028 1026 7987 1013 1028 2380 17704 15537 2033 1997 15969 10225 25318 2007 2010 20868 2890 28943 5897 2875 4680 1012 2035 2010 5691 2024 16880 1010 2021 2025 1999 1037 24665 4017 14663 3560 3168 1012 2009 1005 1055 2062 2066 2002 3065 2149 2054 2057 2123 1005 1056 5987 2000 2156 1011 4050 8146 2008 2175 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.643720 139892314072960 run_classifier.py:465] input_ids: 101 1997 1996 4759 5691 1045 1005 2310 2464 1010 2069 2093 2018 2428 5881 2007 2033 1012 1996 2034 2003 1996 6581 5469 1037 6925 1997 2048 5208 1012 1996 2117 1998 2353 1011 1998 2085 2959 2205 1011 2031 2035 2042 2380 9212 15854 2243 1005 1055 5691 1010 8419 2214 11097 1010 11883 2005 3203 14096 1007 1010 1998 2085 21810 1012 1026 7987 1013 1028 1026 7987 1013 1028 2380 17704 15537 2033 1997 15969 10225 25318 2007 2010 20868 2890 28943 5897 2875 4680 1012 2035 2010 5691 2024 16880 1010 2021 2025 1999 1037 24665 4017 14663 3560 3168 1012 2009 1005 1055 2062 2066 2002 3065 2149 2054 2057 2123 1005 1056 5987 2000 2156 1011 4050 8146 2008 2175 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.646940 139892314072960 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.649317 139892314072960 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:34:37.651730 139892314072960 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:35:27.027877 139892314072960 run_classifier.py:774] Writing example 10000 of 25000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:36:17.290369 139892314072960 run_classifier.py:774] Writing example 20000 of 25000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3aaf1a7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:36:42.307284 139892314072960 estimator.py:201] Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3aaf1a7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:36:56.062644 139892314072960 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:36:59.592092 139892314072960 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_text/bert_text.py:68: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0416 01:36:59.726099 139892314072960 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/bert_text/bert_text.py:68: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0416 01:36:59.774252 139892314072960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0416 01:36:59.865210 139892314072960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0416 01:37:09.559468 139892314072960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:37:11.411206 139892314072960 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:37:11.419819 139892314072960 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:37:16.059111 139892314072960 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:37:22.107625 139892314072960 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:37:22.381495 139892314072960 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:37:39.982789 139892314072960 basic_session_run_hooks.py:594] Saving checkpoints for 0 into output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.6904901, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:37:57.347785 139892314072960 basic_session_run_hooks.py:249] loss = 0.6904901, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.955469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:39:42.007454 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 0.955469\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.46537885, step = 100 (104.665 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:39:42.013267 139892314072960 basic_session_run_hooks.py:247] loss = 0.46537885, step = 100 (104.665 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:41:14.468155 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08154\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.37660474, step = 200 (92.458 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:41:14.470792 139892314072960 basic_session_run_hooks.py:247] loss = 0.37660474, step = 200 (92.458 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.0838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:42:46.735789 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.0838\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.3302382, step = 300 (92.272 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:42:46.742337 139892314072960 basic_session_run_hooks.py:247] loss = 0.3302382, step = 300 (92.272 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08411\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:44:18.976989 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08411\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.26459068, step = 400 (92.237 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:44:18.979727 139892314072960 basic_session_run_hooks.py:247] loss = 0.26459068, step = 400 (92.237 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08372\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:45:51.251859 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08372\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.43613678, step = 500 (92.275 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:45:51.254409 139892314072960 basic_session_run_hooks.py:247] loss = 0.43613678, step = 500 (92.275 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:47:23.575890 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08314\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.28951198, step = 600 (92.329 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:47:23.583642 139892314072960 basic_session_run_hooks.py:247] loss = 0.28951198, step = 600 (92.329 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08337\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:48:55.880745 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08337\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.47476333, step = 700 (92.304 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:48:55.888124 139892314072960 basic_session_run_hooks.py:247] loss = 0.47476333, step = 700 (92.304 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:50:28.214631 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08303\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.45001316, step = 800 (92.331 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:50:28.220448 139892314072960 basic_session_run_hooks.py:247] loss = 0.45001316, step = 800 (92.331 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:52:00.430479 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08441\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.36310583, step = 900 (92.218 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:52:00.437619 139892314072960 basic_session_run_hooks.py:247] loss = 0.36310583, step = 900 (92.218 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:53:32.703122 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08374\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.05745273, step = 1000 (92.273 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:53:32.710119 139892314072960 basic_session_run_hooks.py:247] loss = 0.05745273, step = 1000 (92.273 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:55:04.907304 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08455\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.22279158, step = 1100 (92.201 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:55:04.911328 139892314072960 basic_session_run_hooks.py:247] loss = 0.22279158, step = 1100 (92.201 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08388\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:56:37.168499 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08388\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.13645718, step = 1200 (92.264 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:56:37.175103 139892314072960 basic_session_run_hooks.py:247] loss = 0.13645718, step = 1200 (92.264 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:58:09.418007 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08402\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.07021311, step = 1300 (92.248 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:58:09.423027 139892314072960 basic_session_run_hooks.py:247] loss = 0.07021311, step = 1300 (92.248 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:59:41.955347 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08064\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.08928925, step = 1400 (92.536 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 01:59:41.959242 139892314072960 basic_session_run_hooks.py:247] loss = 0.08928925, step = 1400 (92.536 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08254\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:01:14.330433 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08254\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0175088, step = 1500 (92.376 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:01:14.335063 139892314072960 basic_session_run_hooks.py:247] loss = 0.0175088, step = 1500 (92.376 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08324\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:02:46.646489 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08324\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.10282387, step = 1600 (92.319 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:02:46.654204 139892314072960 basic_session_run_hooks.py:247] loss = 0.10282387, step = 1600 (92.319 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:04:18.953583 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08334\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.20331042, step = 1700 (92.307 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:04:18.961069 139892314072960 basic_session_run_hooks.py:247] loss = 0.20331042, step = 1700 (92.307 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:05:51.253856 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08342\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.01020882, step = 1800 (92.296 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:05:51.256912 139892314072960 basic_session_run_hooks.py:247] loss = 0.01020882, step = 1800 (92.296 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:07:23.566966 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08327\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0065508066, step = 1900 (92.317 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:07:23.573989 139892314072960 basic_session_run_hooks.py:247] loss = 0.0065508066, step = 1900 (92.317 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:08:55.786602 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08437\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0019129433, step = 2000 (92.216 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:08:55.790055 139892314072960 basic_session_run_hooks.py:247] loss = 0.0019129433, step = 2000 (92.216 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:10:28.108946 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08316\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0048808055, step = 2100 (92.326 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:10:28.115813 139892314072960 basic_session_run_hooks.py:247] loss = 0.0048808055, step = 2100 (92.326 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:12:00.244832 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.08535\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0025883205, step = 2200 (92.136 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:12:00.252162 139892314072960 basic_session_run_hooks.py:247] loss = 0.0025883205, step = 2200 (92.136 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.0833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:13:32.555194 139892314072960 basic_session_run_hooks.py:680] global_step/sec: 1.0833\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.001248358, step = 2300 (92.307 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:13:32.559284 139892314072960 basic_session_run_hooks.py:247] loss = 0.001248358, step = 2300 (92.307 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 2343 into output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:14:11.401107 139892314072960 basic_session_run_hooks.py:594] Saving checkpoints for 2343 into output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.0025422743.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:14:21.351165 139892314072960 estimator.py:359] Loss for final step: 0.0025422743.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:14:35.136761 139892314072960 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:14:39.149163 139892314072960 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:14:48.837445 139892314072960 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-04-16T02:14:48Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:14:48.865257 139892314072960 evaluation.py:257] Starting evaluation at 2019-04-16T02:14:48Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:14:51.114797 139892314072960 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0416 02:14:51.125207 139892314072960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from output/model.ckpt-2343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:14:51.129184 139892314072960 saver.py:1270] Restoring parameters from output/model.ckpt-2343\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:14:53.723237 139892314072960 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:14:54.026376 139892314072960 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-04-16-02:18:53\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:18:53.413858 139892314072960 evaluation.py:277] Finished evaluation at 2019-04-16-02:18:53\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 2343: auc = 0.88668, eval_accuracy = 0.88668, f1_score = 0.88632077, false_negatives = 1456.0, false_positives = 1377.0, global_step = 2343, loss = 0.49418914, precision = 0.88913935, recall = 0.88352, true_negatives = 11123.0, true_positives = 11044.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:18:53.416433 139892314072960 estimator.py:1979] Saving dict for global step 2343: auc = 0.88668, eval_accuracy = 0.88668, f1_score = 0.88632077, false_negatives = 1456.0, false_positives = 1377.0, global_step = 2343, loss = 0.49418914, precision = 0.88913935, recall = 0.88352, true_negatives = 11123.0, true_positives = 11044.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2343: output/model.ckpt-2343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0416 02:18:56.315460 139892314072960 estimator.py:2039] Saving 'checkpoint_path' summary for global step 2343: output/model.ckpt-2343\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kaZMjQ0cIw9y",
        "colab_type": "code",
        "outputId": "cb25d829-3673-42a1-e35c-3962b61670af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "result"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc': 0.88668,\n",
              " 'eval_accuracy': 0.88668,\n",
              " 'f1_score': 0.88632077,\n",
              " 'false_negatives': 1456.0,\n",
              " 'false_positives': 1377.0,\n",
              " 'global_step': 2343,\n",
              " 'loss': 0.49418914,\n",
              " 'precision': 0.88913935,\n",
              " 'recall': 0.88352,\n",
              " 'true_negatives': 11123.0,\n",
              " 'true_positives': 11044.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}